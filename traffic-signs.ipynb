{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-22T03:58:25.551630Z","iopub.execute_input":"2021-06-22T03:58:25.551977Z","iopub.status.idle":"2021-06-22T03:58:25.652855Z","shell.execute_reply.started":"2021-06-22T03:58:25.551941Z","shell.execute_reply":"2021-06-22T03:58:25.652109Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport os\nimport sys\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:58:25.655594Z","iopub.execute_input":"2021-06-22T03:58:25.655875Z","iopub.status.idle":"2021-06-22T03:58:25.661983Z","shell.execute_reply.started":"2021-06-22T03:58:25.655849Z","shell.execute_reply":"2021-06-22T03:58:25.661243Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\nEPOCHS = 20\nIMG_WIDTH = 40\nIMG_HEIGHT = 40\nNUM_CATEGORIES = 43\nTEST_SIZE = 0.4\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T04:29:04.490690Z","iopub.execute_input":"2021-06-22T04:29:04.491032Z","iopub.status.idle":"2021-06-22T04:29:04.495524Z","shell.execute_reply.started":"2021-06-22T04:29:04.491003Z","shell.execute_reply":"2021-06-22T04:29:04.494297Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def process_image(img):\n    #apply filters to improve image features\n    #normalize the image\n    img = img - np.mean(img)\n    #sharpen the image\n    avg_img = cv2.boxFilter(img, 3, (3,3))\n    f = img - avg_img\n    return f","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:58:25.674124Z","iopub.execute_input":"2021-06-22T03:58:25.674436Z","iopub.status.idle":"2021-06-22T03:58:25.681056Z","shell.execute_reply.started":"2021-06-22T03:58:25.674411Z","shell.execute_reply":"2021-06-22T03:58:25.680114Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def load_data(data_dir):\n    \"\"\"\n    Load image data from directory `data_dir`.\n\n    Assume `data_dir` has one directory named after each category, numbered\n    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n    number of image files.\n\n    Return tuple `(images, labels)`. `images` should be a list of all\n    of the images in the data directory, where each image is formatted as a\n    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n    be a list of integer labels, representing the categories for each of the\n    corresponding `images`.\n    \"\"\"\n    labels = []\n    images= []\n    for root, _, filenames in os.walk(data_dir):\n        for file in filenames:\n            img = cv2.imread(os.path.join(root,file))\n            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n            img = process_image(img)\n            label = root.split('/').pop()\n            images.append(img)\n            labels.append(label)\n    #print(labels[0])\n    return (images, labels)\n    raise NotImplementedError","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:58:29.532064Z","iopub.execute_input":"2021-06-22T03:58:29.532418Z","iopub.status.idle":"2021-06-22T03:58:29.539528Z","shell.execute_reply.started":"2021-06-22T03:58:29.532384Z","shell.execute_reply":"2021-06-22T03:58:29.538468Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    \"\"\"\n    Returns a compiled convolutional neural network model. Assume that the\n    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n    The output layer should have `NUM_CATEGORIES` units, one for each category.\n    \"\"\"\n    model = tf.keras.Sequential()\n    \n    model.add(layers.Conv2D(\n        32, 3, activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n    ))\n    model.add(layers.Conv2D(\n        32, 3, activation='relu', padding='valid'\n    ))\n   \n    model.add(layers.MaxPooling2D(\n        pool_size=(2,2), strides=(1,1), padding='valid', \n    ))\n    \n    model.add(layers.Dropout(0.25))\n    \n  \n    \n    model.add(layers.Conv2D(\n        64, 3, activation='relu', padding='same'\n    ))\n    model.add(layers.Conv2D(\n        64, 3, activation='relu', padding='same'\n    ))\n    \n    model.add(layers.MaxPooling2D(\n        pool_size=(2,2), strides=(1,1), padding='valid'\n    ))\n    model.add(layers.Dropout(0.25))\n    model.add(\n        layers.Flatten()\n    )\n    \n    \n    model.add(layers.Dense(\n        units=500, activation='relu', use_bias=True, \n    ))\n    model.add(layers.Dense(\n        units=500, activation='relu', use_bias=True, \n    ))\n    model.add(layers.Dropout(0.4))\n    model.add(layers.Dense(units=43, activation='softmax'))\n    \n    model.compile(optimizer='adam', \n                  loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n                  metrics=['accuracy']\n                 )\n    return model\n    raise NotImplementedError","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:58:36.074169Z","iopub.execute_input":"2021-06-22T03:58:36.074534Z","iopub.status.idle":"2021-06-22T03:58:36.084709Z","shell.execute_reply.started":"2021-06-22T03:58:36.074498Z","shell.execute_reply":"2021-06-22T03:58:36.083872Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def Alex_Net_model():\n    \"\"\"\n    returns the compiled CNN model similar to Alexa Net\n    \"\"\"\n    model = keras.Sequential()\n    model.add(layers.Conv2D(\n        8, 3, activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n    ))\n    model.add(layers.Conv2D(\n        8, 3, activation='relu', padding='valid'\n    )\n    )\n    model.add(layers.MaxPooling2D(\n        pool_size=(2,2), strides=(1,1), padding='same'\n    ))\n    model.add(layers.Dropout(0.15))\n    model.add(layers.Conv2D(\n        32, 3, activation='relu', padding='valid'\n    ))\n    model.add(layers.Conv2D(\n        32, 3, activation='relu', padding='valid'\n    ))\n    model.add(layers.MaxPooling2D(\n        pool_size=(2,2), strides=(1,1), padding='same'\n    ))\n    model.add(layers.Conv2D(\n        32, 3, activation='relu', padding='valid'\n    ))\n    model.add(layers.MaxPooling2D(\n        pool_size=(2,2), strides=(1,1), padding='same'\n    ))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(\n        units=235, activation='relu'\n    ))\n    model.add(layers.Dense(\n        units=235, activation='relu'\n    ))\n    model.add(layers.Dropout(0.4))\n    model.add(layers.Dense(\n        units=43, activation='softmax'\n    ))\n    model.compile(\n        optimizer='adam',\n        loss=keras.losses.CategoricalCrossentropy(),\n        metrics=['accuracy']\n    )\n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:00:37.079500Z","iopub.execute_input":"2021-06-22T05:00:37.079851Z","iopub.status.idle":"2021-06-22T05:00:37.090558Z","shell.execute_reply.started":"2021-06-22T05:00:37.079819Z","shell.execute_reply":"2021-06-22T05:00:37.089585Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"images, labels = load_data('/kaggle/input/traffic-data/gtsrb/')\nprint(\"Data Loaded successfully!\")\n# Split data into training and testing sets\nlabels = tf.keras.utils.to_categorical(labels)\nx_train, x_test, y_train, y_test = train_test_split(\n    np.array(images), np.array(labels), test_size=TEST_SIZE\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:58:45.193332Z","iopub.execute_input":"2021-06-22T03:58:45.193687Z","iopub.status.idle":"2021-06-22T04:00:13.222812Z","shell.execute_reply.started":"2021-06-22T03:58:45.193654Z","shell.execute_reply":"2021-06-22T04:00:13.221928Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Data Loaded successfully!\n","output_type":"stream"}]},{"cell_type":"code","source":"model = get_model()\n# Fit model on training data\nmodel.fit(x_train, y_train, epochs=EPOCHS)\n# Evaluate neural network performance\nprint(model.evaluate(x_test,  y_test, verbose=2))","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:32:03.548269Z","iopub.execute_input":"2021-06-22T05:32:03.548631Z","iopub.status.idle":"2021-06-22T05:36:58.186291Z","shell.execute_reply.started":"2021-06-22T05:32:03.548600Z","shell.execute_reply":"2021-06-22T05:36:58.185417Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Epoch 1/20\n500/500 [==============================] - 15s 29ms/step - loss: 7.6572 - accuracy: 0.0834\nEpoch 2/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.9132 - accuracy: 0.7381\nEpoch 3/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.1839 - accuracy: 0.9459\nEpoch 4/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.1100 - accuracy: 0.9703\nEpoch 5/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0744 - accuracy: 0.9787\nEpoch 6/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0769 - accuracy: 0.9788\nEpoch 7/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0454 - accuracy: 0.9872\nEpoch 8/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0550 - accuracy: 0.9869\nEpoch 9/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0520 - accuracy: 0.9874\nEpoch 10/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0873 - accuracy: 0.9817\nEpoch 11/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.1293 - accuracy: 0.9759\nEpoch 12/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0535 - accuracy: 0.9889\nEpoch 13/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0651 - accuracy: 0.9883\nEpoch 14/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0411 - accuracy: 0.9907\nEpoch 15/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0533 - accuracy: 0.9896\nEpoch 16/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0387 - accuracy: 0.9919\nEpoch 17/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0542 - accuracy: 0.9901\nEpoch 18/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0858 - accuracy: 0.9838\nEpoch 19/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0500 - accuracy: 0.9916\nEpoch 20/20\n500/500 [==============================] - 14s 29ms/step - loss: 0.0420 - accuracy: 0.9900\n333/333 - 7s - loss: 0.1813 - accuracy: 0.9814\n[0.1812794953584671, 0.9814189076423645]\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()\nmodel.save('Model1')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:37:07.508975Z","iopub.execute_input":"2021-06-22T05:37:07.509300Z","iopub.status.idle":"2021-06-22T05:37:10.249165Z","shell.execute_reply.started":"2021-06-22T05:37:07.509268Z","shell.execute_reply":"2021-06-22T05:37:10.248284Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Model: \"sequential_24\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_120 (Conv2D)          (None, 38, 38, 32)        896       \n_________________________________________________________________\nconv2d_121 (Conv2D)          (None, 36, 36, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_72 (MaxPooling (None, 35, 35, 32)        0         \n_________________________________________________________________\ndropout_72 (Dropout)         (None, 35, 35, 32)        0         \n_________________________________________________________________\nconv2d_122 (Conv2D)          (None, 35, 35, 64)        18496     \n_________________________________________________________________\nconv2d_123 (Conv2D)          (None, 35, 35, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_73 (MaxPooling (None, 34, 34, 64)        0         \n_________________________________________________________________\ndropout_73 (Dropout)         (None, 34, 34, 64)        0         \n_________________________________________________________________\nflatten_24 (Flatten)         (None, 73984)             0         \n_________________________________________________________________\ndense_72 (Dense)             (None, 500)               36992500  \n_________________________________________________________________\ndense_73 (Dense)             (None, 500)               250500    \n_________________________________________________________________\ndropout_74 (Dropout)         (None, 500)               0         \n_________________________________________________________________\ndense_74 (Dense)             (None, 43)                21543     \n=================================================================\nTotal params: 37,330,111\nTrainable params: 37,330,111\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"alex_model = Alex_Net_model()\n# Fit model on training data\nalex_model.fit(x_train, y_train, epochs=EPOCHS)\n# Evaluate neural network performance\nprint(alex_model.evaluate(x_test,  y_test, verbose=2))","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:00:40.766330Z","iopub.execute_input":"2021-06-22T05:00:40.766726Z","iopub.status.idle":"2021-06-22T05:02:30.266305Z","shell.execute_reply.started":"2021-06-22T05:00:40.766680Z","shell.execute_reply":"2021-06-22T05:02:30.265169Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Epoch 1/20\n500/500 [==============================] - 6s 11ms/step - loss: 2.7744 - accuracy: 0.3911\nEpoch 2/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.4698 - accuracy: 0.8698\nEpoch 3/20\n500/500 [==============================] - 5s 10ms/step - loss: 0.2522 - accuracy: 0.9282\nEpoch 4/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.1575 - accuracy: 0.9533\nEpoch 5/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.1087 - accuracy: 0.9701\nEpoch 6/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0963 - accuracy: 0.9705\nEpoch 7/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0751 - accuracy: 0.9784\nEpoch 8/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0952 - accuracy: 0.9748\nEpoch 9/20\n500/500 [==============================] - 5s 10ms/step - loss: 0.0498 - accuracy: 0.9864\nEpoch 10/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0703 - accuracy: 0.9807\nEpoch 11/20\n500/500 [==============================] - 5s 10ms/step - loss: 0.0506 - accuracy: 0.9852\nEpoch 12/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0608 - accuracy: 0.9836\nEpoch 13/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0685 - accuracy: 0.9814\nEpoch 14/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0536 - accuracy: 0.9867\nEpoch 15/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0395 - accuracy: 0.9905\nEpoch 16/20\n500/500 [==============================] - 5s 10ms/step - loss: 0.0415 - accuracy: 0.9895\nEpoch 17/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0380 - accuracy: 0.9907\nEpoch 18/20\n500/500 [==============================] - 5s 10ms/step - loss: 0.0530 - accuracy: 0.9879\nEpoch 19/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0518 - accuracy: 0.9886\nEpoch 20/20\n500/500 [==============================] - 5s 11ms/step - loss: 0.0315 - accuracy: 0.9933\n333/333 - 2s - loss: 0.0829 - accuracy: 0.9854\n[0.08288948237895966, 0.9853603839874268]\n","output_type":"stream"}]},{"cell_type":"code","source":"alex_model.summary()\nalex_model.save('Alex_Model_2')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:41:01.767016Z","iopub.execute_input":"2021-06-22T05:41:01.767475Z","iopub.status.idle":"2021-06-22T05:41:03.727064Z","shell.execute_reply.started":"2021-06-22T05:41:01.767427Z","shell.execute_reply":"2021-06-22T05:41:03.726202Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Model: \"sequential_23\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_115 (Conv2D)          (None, 38, 38, 8)         224       \n_________________________________________________________________\nconv2d_116 (Conv2D)          (None, 36, 36, 8)         584       \n_________________________________________________________________\nmax_pooling2d_69 (MaxPooling (None, 36, 36, 8)         0         \n_________________________________________________________________\ndropout_69 (Dropout)         (None, 36, 36, 8)         0         \n_________________________________________________________________\nconv2d_117 (Conv2D)          (None, 34, 34, 32)        2336      \n_________________________________________________________________\nconv2d_118 (Conv2D)          (None, 32, 32, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_70 (MaxPooling (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_119 (Conv2D)          (None, 30, 30, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_71 (MaxPooling (None, 30, 30, 32)        0         \n_________________________________________________________________\ndropout_70 (Dropout)         (None, 30, 30, 32)        0         \n_________________________________________________________________\nflatten_23 (Flatten)         (None, 28800)             0         \n_________________________________________________________________\ndense_69 (Dense)             (None, 235)               6768235   \n_________________________________________________________________\ndense_70 (Dense)             (None, 235)               55460     \n_________________________________________________________________\ndropout_71 (Dropout)         (None, 235)               0         \n_________________________________________________________________\ndense_71 (Dense)             (None, 43)                10148     \n=================================================================\nTotal params: 6,855,483\nTrainable params: 6,855,483\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -r ./Alex_Model_2","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:40:48.197755Z","iopub.execute_input":"2021-06-22T05:40:48.198106Z","iopub.status.idle":"2021-06-22T05:40:48.924328Z","shell.execute_reply.started":"2021-06-22T05:40:48.198069Z","shell.execute_reply":"2021-06-22T05:40:48.923117Z"},"trusted":true},"execution_count":82,"outputs":[]}]}